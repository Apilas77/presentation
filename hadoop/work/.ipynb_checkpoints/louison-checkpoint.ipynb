{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-height",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/jovyan/work/data/new.csv;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2f97cac2bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/new.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcorona\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcorona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/jovyan/work/data/new.csv;"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "path = \"./data/new.csv\"\n",
    "corona = spark.read.format('csv').options(header=True, sep=\";\").load(path)\n",
    "corona.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre d'hospitalisation dans le département 19 \n",
    "coronaDep19 = corona.filter(corona[\"dep\"]==\"19\")\n",
    "coronaDep19.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jour ou le nombre moyen d'hospitalisation est le plus élévé \n",
    "coronaDays = corona.groupBy(\"jour\")\n",
    "averagePerDays = coronaDays.agg({\"nb\": \"mean\"})\n",
    "\n",
    "dayRowWithBiggestAverage = averagePerDays.sort(['avg(nb)'], ascending=False).collect()[0]\n",
    "\n",
    "dayWithBiggestAverage = dayRowWithBiggestAverage['jour']\n",
    "\n",
    "dayWithBiggestAverage\n",
    "\n",
    "#averagePerDays.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jour ou le nombre moyen d'hospitalisation est le moins élévé \n",
    "coronaDays = corona.groupBy(\"jour\")\n",
    "averagePerDays = coronaDays.agg({\"nb\": \"mean\"})\n",
    "\n",
    "dayRowWithLowestAverage = averagePerDays.sort(['avg(nb)'], ascending=True).collect()[0]\n",
    "\n",
    "dayWithLowestAverage = dayRowWithLowestAverage['jour']\n",
    "\n",
    "dayWithLowestAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste du + petit nombre de cas au + grand\n",
    "coronaDays = corona.groupBy(\"jour\")\n",
    "averagePerDays = coronaDays.agg({\"nb\": \"mean\"})\n",
    "\n",
    "averagePerDays.sort(['avg(nb)'], ascending=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des jours pour les données\n",
    "listOfDays = corona.groupBy('jour').agg({}).collect()\n",
    "listOfDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre d'hospitalisation par departement sur les deux dernières semaines \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.now()\n",
    "twoWeeksAgo = today - timedelta(14)\n",
    "\n",
    "twoWeeksAgoFormated = datetime.strftime(twoWeeksAgo, \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "recentList = corona.filter(corona[\"jour\"]>twoWeeksAgoFormated)\n",
    "recentList.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Somme tous les cas par départements sous deux semaines (trié par nombre de cas hospitalisé ascendant)\n",
    "\n",
    "recentListSum = recentList.groupBy('dep').agg({\"nb\": \"sum\"})\n",
    "recentListSum.sort(['sum(nb)']).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2/3 pandas a faire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} geopandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-lebanon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} descartes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from matplotlib import pyplot\n",
    "import geopandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "path = \"./data/new.csv\"\n",
    "corona = spark.read.format('csv').options(header=True, sep=\";\").load(path)\n",
    "corona.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCasesByDep = corona.groupBy('dep').agg({\"nb\": \"mean\"}).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"./data/departements/departements.shp\"\n",
    "map_df = geopandas.read_file(fp)\n",
    "map_df.head()\n",
    "\n",
    "def genFrance(variable, data, title):\n",
    "    merged = map_df.set_index('code_insee').join(data.set_index('dep'))\n",
    "    # set the range for the choropleth\n",
    "    vmin, vmax = 120, 220\n",
    "    # create figure and axes for Matplotlib\n",
    "    fig, ax = pyplot.subplots(1, figsize=(10, 6))\n",
    "\n",
    "    map = merged.plot(column=variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8', figsize=(28, 24))\n",
    "\n",
    "    map.set_xlim(-10, 15)\n",
    "    map.set_ylim(40, 55)\n",
    "    map.axis('off')\n",
    "    map.set_title(title, fontdict={\"fontsize\": \"25\", \"fontweight\" : \"3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "genFrance('avg(nb)', avgCasesByDep, \"Hospitalisations moyennes en France, par departement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-smooth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " avgCasesByDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # plus pratique d'utiliser panda pour parser le csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "lastWeek = datetime.now() - timedelta(7)\n",
    "lastWeekFormatted = datetime.strftime(lastWeek, '%Y-%m-%d')\n",
    "\n",
    "coronaPandas = pd.read_csv(\"./data/new.csv\", sep=\";\")\n",
    "\n",
    "coronaPandasList = coronaPandas['jour'].tolist()\n",
    "\n",
    "lastWeek = datetime.now()\n",
    "uniqueDays = [j for j in set(coronaPandasList) if j > lastWeekFormatted]\n",
    "uniqueDays.sort()\n",
    "\n",
    "for jour in uniqueDays:\n",
    "    genFrance('nb', coronaPandas[jour == coronaPandas['jour']], 'Nombre d\\'hospitalisations au jour ' + jour)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toutes les données sont très similaires, il y a donc très peu de différences sur les maps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
