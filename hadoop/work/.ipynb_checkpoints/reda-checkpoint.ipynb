{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-newton",
   "metadata": {},
   "source": [
    "# 1.1)Dataset regroupant les régions,classe d'âge, reanimation,hostpitalisation, et guérison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sound-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reg: string (nullable = true)\n",
      " |-- cl_age90: string (nullable = true)\n",
      " |-- jour: string (nullable = true)\n",
      " |-- hosp: string (nullable = true)\n",
      " |-- rea: string (nullable = true)\n",
      " |-- rad: string (nullable = true)\n",
      " |-- dc: string (nullable = true)\n",
      "\n",
      "+---+--------+----------+----+---+---+---+\n",
      "|reg|cl_age90|      jour|hosp|rea|rad| dc|\n",
      "+---+--------+----------+----+---+---+---+\n",
      "| 01|       0|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      09|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      19|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      29|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      39|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      49|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      59|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      69|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      79|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      89|2020-03-18|   0|  0|  0|  0|\n",
      "| 01|      90|2020-03-18|   0|  0|  0|  0|\n",
      "| 02|       0|2020-03-18|  16|  5|  0|  1|\n",
      "| 02|      09|2020-03-18|   0|  0|  0|  0|\n",
      "| 02|      19|2020-03-18|   0|  0|  0|  0|\n",
      "| 02|      29|2020-03-18|   2|  1|  0|  0|\n",
      "| 02|      39|2020-03-18|   2|  0|  0|  0|\n",
      "| 02|      49|2020-03-18|   2|  1|  0|  0|\n",
      "| 02|      59|2020-03-18|   5|  0|  0|  0|\n",
      "| 02|      69|2020-03-18|   4|  3|  0|  0|\n",
      "| 02|      79|2020-03-18|   1|  0|  0|  0|\n",
      "+---+--------+----------+----+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/donnees-hospitalieres-classe-age-covid19-2021-01-20-19h03.csv\"\n",
    "df = spark.read.format('csv').options(header=True, inferShema=True, delimiter=';').load(path)\n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-conjunction",
   "metadata": {},
   "source": [
    "# 1) Aperçu général"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "substantial-ancient",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "|summary|               reg|         cl_age90|              hosp|               rea|              rad|               dc|\n",
      "+-------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "|  count|             61182|            61182|             61182|             61182|            61182|            61182|\n",
      "|   mean|39.388888888888886|48.27272727272727|164.99123925337517|22.707806217514957|976.5033506586905|232.1244810565199|\n",
      "| stddev| 32.28741109923755|30.26601231024996| 578.2811559515713| 90.83477149520677|3174.888206060533|801.5843552179239|\n",
      "|    min|                01|                0|                 0|                 0|                0|                0|\n",
      "|    max|                94|               90|               999|                99|              999|              999|\n",
      "+-------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Describe\n",
    "df_reduce = df.drop(\"jour\")\n",
    "df_summary = df_reduce.describe()\n",
    "df_summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-database",
   "metadata": {},
   "source": [
    "# 2)Moyenne de décès par régions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "willing-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|reg|           avg(dc)|\n",
      "+---+------------------+\n",
      "| 11|1425.2156516622535|\n",
      "| 01|11.911738746690203|\n",
      "| 28|112.41629891144454|\n",
      "| 52|108.72109443954105|\n",
      "| 27| 227.2647837599294|\n",
      "| 75|118.64607237422771|\n",
      "| 93|258.86231244483673|\n",
      "| 03| 6.929096793174463|\n",
      "| 02|3.9711679905854664|\n",
      "| 44|  677.531332744925|\n",
      "| 53| 60.54310091203295|\n",
      "| 06|4.6163577522800825|\n",
      "| 84| 475.4365989997058|\n",
      "| 24|117.50426596057665|\n",
      "| 32| 403.2953809944101|\n",
      "| 04| 3.160341276846131|\n",
      "| 94|12.505442777287438|\n",
      "| 76|149.70962047661078|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "moy_dc_rg = df.groupBy('reg').agg({\"dc\":\"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-walnut",
   "metadata": {},
   "source": [
    "# 3)Max de décès et de rétablissements par régions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medium-toner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+\n",
      "|cl_age90|max(rad)|max(dc)|\n",
      "+--------+--------+-------+\n",
      "|       0|    9981|    999|\n",
      "|      09|      99|      3|\n",
      "|      19|      99|      4|\n",
      "|      29|     997|      9|\n",
      "|      39|     999|      9|\n",
      "|      49|     998|     99|\n",
      "|      59|     999|     99|\n",
      "|      69|     999|    992|\n",
      "|      79|     999|    997|\n",
      "|      89|     999|    997|\n",
      "|      90|     998|    998|\n",
      "+--------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_rad_dc = df.groupBy('cl_age90').agg({\"dc\":\"max\",\"rad\":\"max\"}).sort('cl_age90').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-genome",
   "metadata": {},
   "source": [
    "# 4)Moyenne des admis en réanimation,hospitalisation et décès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exact-quarterly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+-------------------+\n",
      "|cl_age90|          avg(rad)|         avg(hosp)|           avg(rea)|\n",
      "+--------+------------------+------------------+-------------------+\n",
      "|       0| 5389.694174757282| 911.1129090255304| 125.39679971233369|\n",
      "|      09| 56.50071916576771| 2.538115785688601|0.44156778137360664|\n",
      "|      19| 47.55231930960086| 2.759439050701187|0.44156778137360664|\n",
      "|      29|  192.351492268968| 9.253505933117584| 1.1049982020855806|\n",
      "|      39| 322.3653362099964| 18.46997482919813|  3.118482560230133|\n",
      "|      49| 477.8383674937073| 35.98759439050701| 7.8042071197411005|\n",
      "|      59| 772.7603380079108| 81.56418554476807| 20.724020136641496|\n",
      "|      69| 954.5688601222582|149.65336209996403| 39.277058612010066|\n",
      "|      79|1018.6612729234089|213.59726717008272|  40.22761596548004|\n",
      "|      89|1038.3532901833873|  260.123696512046| 10.257281553398059|\n",
      "|      90|470.89068680330814| 129.8435814455232| 0.9922689679971234|\n",
      "+--------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_moy_age = df_reduce.groupBy(['cl_age90']).agg({\"rea\":\"mean\",\"rad\":\"mean\",\"hosp\":\"mean\"}).sort(\"cl_age90\")\n",
    "df_moy_age.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weekly-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-license",
   "metadata": {},
   "source": [
    "**Transformation de la date en date.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "direct-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "@udf(returnType = TimestampType())\n",
    "def transform_timestamp_in_date(timestamp):\n",
    "    from datetime import datetime\n",
    "    return datetime.strptime(timestamp, \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mental-wisdom",
   "metadata": {},
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 223, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 212, in _batched\n    for item in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 88, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-8-e170341921cc>\", line 6, in transform_timestamp_in_date\n  File \"/usr/lib/python3.8/_strptime.py\", line 568, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/usr/lib/python3.8/_strptime.py\", line 349, in _strptime\n    raise ValueError(\"time data %r does not match format %r\" %\nValueError: time data '2020-03-18' does not match format '%d/%m/%Y'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1b2f1a7b4431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_with_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datestamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform_timestamp_in_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jour\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_with_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 605, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 597, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 223, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 212, in _batched\n    for item in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 88, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 107, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-8-e170341921cc>\", line 6, in transform_timestamp_in_date\n  File \"/usr/lib/python3.8/_strptime.py\", line 568, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/usr/lib/python3.8/_strptime.py\", line 349, in _strptime\n    raise ValueError(\"time data %r does not match format %r\" %\nValueError: time data '2020-03-18' does not match format '%d/%m/%Y'\n"
     ]
    }
   ],
   "source": [
    "df_with_date = df.withColumn('datestamp',transform_timestamp_in_date(\"jour\"))\n",
    "df_with_date.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-middle",
   "metadata": {},
   "source": [
    "\n",
    "# 5)Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/donnees-hospitalieres-classe-age-covid19-2021-01-20-19h03.csv\", sep=\";\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-federation",
   "metadata": {},
   "source": [
    "# 5-1)Décès par classe d'âge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max_dc = data.groupby('cl_age90').agg({'dc':'sum'})\n",
    "data_max_dc.plot.bar(title=\"\", figsize=(20, 8))\n",
    "print(data_max_dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-blogger",
   "metadata": {},
   "source": [
    "# 5-2)La région la plus touchée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-transparency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_max_dc_reg = data.groupby('reg').agg({'dc':'max'})\n",
    "data_max_dc_reg.plot.bar(title=\"les 10 premières équipes qui ont le plus gros nombre de buts à domicile\", figsize=(20, 8))\n",
    "print(data_max_dc_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-prime",
   "metadata": {},
   "source": [
    "# 5-3)Moyenne des décès par classe d'âge avec pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moyenne des dc par tranche d'âge avec pandas\n",
    "data_moy_age = data.drop('reg',axis=1).groupby(['cl_age90']).mean()\n",
    "data_moy_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-stamp",
   "metadata": {},
   "source": [
    "**Indexer suivant la colonne des jours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mettre les jours en index pour mieux manipuler la suite des plot\n",
    "data = df_with_date.toPandas()\n",
    "data = data.set_index('datestamp')\n",
    "data.dc = pd.to_numeric(data.dc, errors='coerce')\n",
    "data.rad = pd.to_numeric(data.rad, errors='coerce')\n",
    "data.hosp = pd.to_numeric(data.hosp, errors='coerce')\n",
    "data.rea = pd.to_numeric(data.rea, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-unknown",
   "metadata": {},
   "source": [
    "# 5-4)Comparaison entre la moyenne et max de décès (semaine,mois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-characteristic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "data.loc['2020', 'dc'].plot()\n",
    "data.loc['2020', 'dc'].resample('M').mean().plot(label='moyenne par mois', lw=3, ls=':', alpha=0.8)\n",
    "data.loc['2020', 'dc'].resample('W').mean().plot(label='moyenne par semaine', lw=2, ls='--', alpha=0.8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-richards",
   "metadata": {},
   "source": [
    "# 5-4)Comparaison entre la moyenne et max des rétablissements (semaine,mois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "data.loc['2020', 'rad'].plot()\n",
    "data.loc['2020', 'rad'].resample('M').mean().plot(label='moyenne par mois', lw=3, ls=':', alpha=0.8)\n",
    "data.loc['2020', 'rad'].resample('W').mean().plot(label='moyenne par semaine', lw=2, ls='--', alpha=0.8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-teach",
   "metadata": {},
   "source": [
    "# 5-5)Moyenne des décès et des guéris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.ylabel(\"moyenne de décès et de guérisons\")\n",
    "data['2020']['dc'].resample('M').mean().plot(label=\"moyenne de décès par mois durant 2020\", lw=3, ls=\":\", alpha=0.8)\n",
    "data['2020']['rad'].resample('M').mean().plot(label=\"moyenne guérisons par mois durant 2020\", lw=2, ls=\"--\", alpha=0.8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-tackle",
   "metadata": {},
   "source": [
    "# 5-6)Moyenne des admis en réanimation et des guéris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.ylabel(\"moyenne des hospitalisés, guéris et décèdès\")\n",
    "data['2020']['hosp'].resample('M').mean().plot(label=\"moyenne d'hospitalisés par mois durant 2020\", lw=3, ls=\":\", alpha=0.8)\n",
    "data['2020']['rea'].resample('M').mean().plot(label=\"moyenne réanimation par mois durant 2020\", lw=2, ls=\"--\", alpha=0.8)\n",
    "data['2020']['dc'].resample('M').mean().plot(label=\"moyenne de décès par mois durant 2020\", lw=1, ls=\"dashed\", alpha=0.8)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-cover",
   "metadata": {},
   "source": [
    "# 5-7) Mean,Std,Max,Min :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "deces = data['2020']['dc'].resample('M').agg(['mean','std','max','min'])\n",
    "\n",
    "# Le graphe\n",
    "plt.figure(figsize=(25,12))\n",
    "plt.ylabel(\"nombre de décès\")\n",
    "deces['mean'].plot(label=\"moyenne par mois 2020\")\n",
    "plt.fill_between(deces.index, deces['max'], deces['min'], alpha=0.1, label=\"min-max décès par mois\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-daisy",
   "metadata": {},
   "source": [
    "# 5-8) Mean,Std,Max,Min :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "deces = data['2020']['rad'].resample('M').agg(['mean','std','max','min'])\n",
    "\n",
    "# Le graphe\n",
    "plt.figure(figsize=(25,12))\n",
    "plt.ylabel(\"nombre de décès\")\n",
    "deces['mean'].plot(label=\"moyenne par mois 2020\")\n",
    "plt.fill_between(deces.index, deces['max'], deces['min'], alpha=0.1, label=\"min-max décès par mois\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-intersection",
   "metadata": {},
   "source": [
    "# Le DataSet n°2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-invasion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv('./data/donnees-hospitalieres-covid19-2021-01-20-19h03.csv', sep=\";\")\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.drop(dataSet.loc[dataSet['sexe']== 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-stuff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataSet, hue=\"sexe\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
